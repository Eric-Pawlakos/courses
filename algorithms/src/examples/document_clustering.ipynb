{
 "metadata": {
  "name": "",
  "signature": "sha256:110147c729faaba442fd67bd7a345a99f5a3f988baa6d776bbe452014459e8d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
      "\n",
      "import logging\n",
      "from optparse import OptionParser\n",
      "import sys\n",
      "from time import time\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "# Display progress logs on stdout\n",
      "logging.basicConfig(level=logging.INFO,\n",
      "                    format='%(asctime)s %(levelname)s %(message)s')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# parse commandline arguments\n",
      "#op = OptionParser()\n",
      "#op.add_option(\"--no-minibatch\",\n",
      "#              action=\"store_false\", dest=\"minibatch\", default=True,\n",
      "#              help=\"Use ordinary k-means algorithm.\")\n",
      "\n",
      "#print __doc__\n",
      "#op.print_help()\n",
      "\n",
      "#(opts, args) = op.parse_args()\n",
      "#if len(args) > 0:\n",
      "#    op.error(\"this script takes no arguments.\")\n",
      "#    sys.exit(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Load some categories from the training set\n",
      "categories = [\n",
      "    'alt.atheism',\n",
      "    'talk.religion.misc',\n",
      "    'comp.graphics',\n",
      "    'sci.space',\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Uncomment the following to do the analysis on all the categories\n",
      "#categories = None\n",
      "\n",
      "print \"Loading 20 newsgroups dataset for categories:\"\n",
      "print categories\n",
      "\n",
      "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
      "                             shuffle=True, random_state=42)\n",
      "\n",
      "print \"%d documents\" % len(dataset.data)\n",
      "print \"%d categories\" % len(dataset.target_names)\n",
      "print\n",
      "\n",
      "labels = dataset.target\n",
      "true_k = np.unique(labels).shape[0]\n",
      "\n",
      "print \"Extracting features from the training dataset using a sparse vectorizer\"\n",
      "t0 = time()\n",
      "vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n",
      "                             stop_words='english')\n",
      "X = vectorizer.fit_transform(dataset.data)\n",
      "\n",
      "print \"done in %fs\" % (time() - t0)\n",
      "print \"n_samples: %d, n_features: %d\" % X.shape\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:sklearn.datasets.twenty_newsgroups:Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading 20 newsgroups dataset for categories:\n",
        "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "3387 documents"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4 categories\n",
        "\n",
        "Extracting features from the training dataset using a sparse vectorizer\n",
        "done in 1.862331s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "n_samples: 3387, n_features: 10000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############################################################################\n",
      "# Do the actual clustering\n",
      "\n",
      "#if opts.minibatch:\n",
      "#    km = MiniBatchKMeans(k=true_k, init='k-means++', n_init=1,\n",
      "#                         init_size=1000,\n",
      "#                         batch_size=1000, verbose=1)\n",
      "#else:\n",
      "km = KMeans(k=true_k, init='random', max_iter=100, n_init=1, verbose=1)\n",
      "\n",
      "print \"Clustering sparse data with %s\" % km\n",
      "t0 = time()\n",
      "km.fit(X)\n",
      "print \"done in %0.3fs\" % (time() - t0)\n",
      "print\n",
      "\n",
      "print \"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_)\n",
      "print \"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_)\n",
      "print \"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_)\n",
      "print \"Adjusted Rand-Index: %.3f\" % \\\n",
      "    metrics.adjusted_rand_score(labels, km.labels_)\n",
      "print \"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(\n",
      "    X, labels, sample_size=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "__init__() got an unexpected keyword argument 'k'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-8097560e6876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#                         batch_size=1000, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Clustering sparse data with %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'k'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}